{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 521 Final Report\n",
    "## Predicting Quarterly Earnings per Share with Time Series Data\n",
    "#### RNN by Franco Rey\n",
    "#### Gradient Boosted Regressor Trees by Hank Beck\n",
    "#### Random Forest Regression by Bhavesh\n",
    "#### Kmean Regime Clustering and Markov Chain by Kevin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "    - What is the problem?\n",
    "    - What are traditional methods for forecasting returns?\n",
    "    - What is the benefit of machine learning to this problem\n",
    "    - What models did we choose to explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data\n",
    "\n",
    "## Target\n",
    "    - Reported EPS\n",
    "    \n",
    "## Features\n",
    "    \n",
    "## Data Sources\n",
    "    - Yahoo finance\n",
    "    - Alpha Vantage\n",
    "    \n",
    "## Things that needed to be accounted for\n",
    "    - look ahead bias\n",
    "    - Information available when predictions are to be made\n",
    "    - Stationarity \n",
    "    - survivorship Bias\n",
    "    \n",
    "## Pros of the data set\n",
    "\n",
    "## Cons of dataset\n",
    "\n",
    "## Ways the dataset could be theorectically improved if more data available\n",
    "    - longer time period\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fetching and Cleaning\n",
    "I will work here before merging with main so we have a backup in case someone messes up a merge with their independent branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Modules for fetching data\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "AV_api_key = os.getenv(\"ALPHA_VANTAGE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data retrieval and cleanup helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def DeleteEmptyCSVs(CSVToCheck):\n",
    "    # Function to delete any csvs that were created by an attempted data retrieval\n",
    "    # but are empty of data\n",
    "    if os.path.isfile(CSVToCheck):\n",
    "        # Count the number of lines in the file\n",
    "        with open(CSVToCheck, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            line_count = sum(1 for row in reader)\n",
    "        \n",
    "        print(f\"The file {CSVToCheck} has {line_count} lines.\")\n",
    "\n",
    "        # Check if the line count is less 3 (header and empty line)\n",
    "        if line_count < 3:\n",
    "            print(f\"{CSVToCheck} seems empty. Deleting the file.\")\n",
    "            os.remove(CSVToCheck)\n",
    "        else:\n",
    "            print(f\"{CSVToCheck} seems to have data.\")\n",
    "    else:\n",
    "        print(f\"{CSVToCheck} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getYahoo(tckr, tckr_csv):\n",
    "    \n",
    "    if not os.path.isfile(tckr_csv):\n",
    "        print(\"Retrieving \"+tckr+\" Data from Yahoo...\")\n",
    "        try:\n",
    "            tckr_data = yf.download(tckr, start=START_DATE_yahoo, end=END_DATE_yahoo)\n",
    "            print(\"saving data to csv\")\n",
    "            tckr_data.to_csv(tckr_csv)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to retrieve data: {e}\")\n",
    "    else:\n",
    "        print(tckr+\" data already saved in csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDividends(tckr):\n",
    "    ticker = yf.Ticker(tckr)\n",
    "    dividends_series = ticker.dividends\n",
    "    csvFile = '.\\data_files\\\\'\n",
    "    csvFile = csvFile + tckr + 'dividends.csv'\n",
    "    dividends_series.to_csv(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEarningsFromAlphaVantage(stock_ticker, data_folder = 'data_files'):\n",
    "    # Request from API\n",
    "    url = f'https://www.alphavantage.co/query?function=EARNINGS&symbol={stock_ticker}&apikey={AV_api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    quarterly_file =  stock_ticker + 'quarterlyEarnings.csv'\n",
    "    #annual_file =  stock_ticker + 'annualEarnings.csv'\n",
    "    quarterly_csv = os.path.join(data_folder, quarterly_file)\n",
    "    #annual_csv = os.path.join(data_folder, annual_file)\n",
    "    # Parse the response to get EPS data and save it as a CSV file\n",
    "    quarterly_earnings = data['quarterlyEarnings']\n",
    "    #annual_earnings = data['annualEarnings']\n",
    "    if not os.path.isfile(quarterly_csv):\n",
    "        with open(quarterly_csv, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Fiscal Date','Estimated EPS', 'Reported EPS'])  # Write header row\n",
    "            for earnings_data in quarterly_earnings:\n",
    "                fiscal_date = earnings_data['fiscalDateEnding']\n",
    "                estimated_eps = earnings_data['estimatedEPS']\n",
    "                reported_eps = earnings_data['reportedEPS']\n",
    "                writer.writerow([fiscal_date, estimated_eps, reported_eps])\n",
    "    else:\n",
    "        print(\"Quarterly Earnings CSV already present\")\n",
    "    # Report save\n",
    "        \n",
    "    print(f\" Quarterly Earnings data saved to {quarterly_csv}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BalanceSheetFromAlphaVantage(stock_ticker, data_folder = 'data_files'):\n",
    "    # Request from API\n",
    "    url = 'https://www.alphavantage.co/query?function=BALANCE_SHEET&symbol=IBM&apikey=demo'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    quarterly_file =  stock_ticker + 'quarterlyBalSheet.csv'\n",
    "    #annual_file =  stock_ticker + 'annualEarnings.csv'\n",
    "    quarterly_csv = os.path.join(data_folder, quarterly_file)\n",
    "    #annual_csv = os.path.join(data_folder, annual_file)\n",
    "    # Parse the response to get EPS data and save it as a CSV file\n",
    "    quarterly_reports = data['quarterlyReports']\n",
    "    #annual_earnings = data['annualEarnings']\n",
    "    if not os.path.isfile(quarterly_csv):\n",
    "        with open(quarterly_csv, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            balance_sheet_items = list(quarterly_reports[0].keys())\n",
    "            writer.writerow(balance_sheet_items)  # Write header row\n",
    "            for report in quarterly_reports:\n",
    "                curr_row = []\n",
    "                for item in balance_sheet_items:\n",
    "                    curr_row.append(report[item])\n",
    "                writer.writerow(curr_row)\n",
    "    else:\n",
    "        print(\"Quarterly Earnings CSV already present\")\n",
    "    # Report save\n",
    "        \n",
    "    print(f\" Quarterly Earnings data saved to {quarterly_csv}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Initial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sourced from yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE_yahoo =\"1990-01-01\"\n",
    "END_DATE_yahoo = \"2024-05-30\"\n",
    "\n",
    "# Larger Market trends \n",
    "\n",
    "# S&P 500\n",
    "sp500_ticker = '^GSPC'\n",
    "sp500_csv = '.\\data_files\\sp500_RawData.csv'\n",
    "START_DATE_sp500 = START_DATE_yahoo\n",
    "END_DATE_sp500 = END_DATE_yahoo\n",
    "\n",
    "# CBOE Volatility Index (VIX)\n",
    "vix_ticker = '^VIX'\n",
    "vix_csv = '.\\data_files\\VIX_RawData.csv'\n",
    "START_DATE_vix = START_DATE_yahoo\n",
    "END_DATE_vix = END_DATE_yahoo\n",
    "\n",
    "# Large Cap Stocks\n",
    "\n",
    "# Microsoft (MSFT)\n",
    "micro_ticker = 'MSFT'\n",
    "micro_csv = '.\\data_files\\MSFT_RawData.csv'\n",
    "micro_earnings_csv = '.\\data_files\\MSFTquarterlyEarnings.csv'\n",
    "micro_balSht_csv = '.\\data_files\\MSFTquarterlyBalSheet.csv'\n",
    "START_DATE_msft = START_DATE_yahoo\n",
    "END_DATE_msft = END_DATE_yahoo\n",
    "\n",
    "# General Electric (GE)\n",
    "general_elec_ticker = 'GE'\n",
    "ge_csv = '.\\data_files\\GE_RawData.csv'\n",
    "START_DATE_ge = START_DATE_yahoo\n",
    "END_DATE_ge = END_DATE_yahoo\n",
    "\n",
    "# Johnson and Johnson (JNJ)\n",
    "jj_ticker = 'JNJ'\n",
    "jj_csv = '.\\data_files\\JNJ_RawData.csv'\n",
    "jj_earnings_csv = '.\\data_files\\JNJquarterlyEarnings.csv'\n",
    "jj_balSht_csv = '.\\data_files\\JNJquarterlyBalSheet.csv'\n",
    "jj_dividend_csv = '.\\data_files\\JNJdividends.csv'\n",
    "START_DATE_jj = START_DATE_yahoo\n",
    "END_DATE_jj = END_DATE_yahoo\n",
    "\n",
    "# Coca Cola (KO)\n",
    "cc_ticker = 'KO'\n",
    "cc_csv = '.\\data_files\\KO_RawData.csv'\n",
    "START_DATE_cc = START_DATE_yahoo\n",
    "END_DATE_cc = END_DATE_yahoo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 (representative of of larger market trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^GSPC data already saved in csv\n"
     ]
    }
   ],
   "source": [
    "#getYahoo(sp500_ticker, sp500_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIX (overall market volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving ^VIX Data from Yahoo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#getYahoo(vix_ticker,vix_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Johnson and Johnson Historical Stock Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving JNJ Data from Yahoo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#getYahoo(jj_ticker, jj_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microsoft Historical Stock Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving MSFT Data from Yahoo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#getYahoo(micro_ticker,micro_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividend data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getDividends(jj_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getDividends(micro_ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Vantage Accounting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BalanceSheetFromAlphaVantage(stock_ticker=micro_ticker)\n",
    "#GetEarningsFromAlphaVantage(stock_ticker= micro_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Quarterly Earnings data saved to data_files\\JNJquarterlyBalSheet.csv\n",
      " Quarterly Earnings data saved to data_files\\JNJquarterlyEarnings.csv\n"
     ]
    }
   ],
   "source": [
    "#BalanceSheetFromAlphaVantage(stock_ticker=jj_ticker)\n",
    "#GetEarningsFromAlphaVantage(stock_ticker= jj_ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FROM CSVs Create Collated Data Frame\n",
    "\n",
    "Features to Extract:\n",
    "\n",
    "    - reported Earnings Per Share\n",
    "    - Total Assets\n",
    "    - Accruals \n",
    "    - Equity Ratio \n",
    "    - Cash Dividends Paid Since last Quarter\n",
    "    - VIX Lagged By By several steps out\n",
    "        - Can achieve some granularity this way despite looking to make quarterly predictions for earnings\n",
    "    - S&P Lagged for several steps \n",
    "        - Can provide information on how it has moved over the last several weeks not just quarter to quarter snapshots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Daily_Return_percent_SP</th>\n",
       "      <th>Daily_Return_percent_VIX</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_Return_percent</th>\n",
       "      <th>Estimated EPS</th>\n",
       "      <th>Reported EPS</th>\n",
       "      <th>totalAssets</th>\n",
       "      <th>Equity Ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>0.017799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>-0.002586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>-0.008613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>-0.009756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-08</th>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Daily_Return_percent_SP  Daily_Return_percent_VIX  Dividends  \\\n",
       "Date                                                                       \n",
       "1990-01-02                 0.017799                       0.0        NaN   \n",
       "1990-01-03                -0.002586                       0.0        NaN   \n",
       "1990-01-04                -0.008613                       0.0        NaN   \n",
       "1990-01-05                -0.009756                       0.0        NaN   \n",
       "1990-01-08                 0.004514                       0.0        NaN   \n",
       "\n",
       "            Volume  Daily_Return_percent  Estimated EPS  Reported EPS  \\\n",
       "Date                                                                    \n",
       "1990-01-02     NaN                   NaN            NaN           NaN   \n",
       "1990-01-03     NaN                   NaN            NaN           NaN   \n",
       "1990-01-04     NaN                   NaN            NaN           NaN   \n",
       "1990-01-05     NaN                   NaN            NaN           NaN   \n",
       "1990-01-08     NaN                   NaN            NaN           NaN   \n",
       "\n",
       "            totalAssets  Equity Ratio  \n",
       "Date                                   \n",
       "1990-01-02          NaN           NaN  \n",
       "1990-01-03          NaN           NaN  \n",
       "1990-01-04          NaN           NaN  \n",
       "1990-01-05          NaN           NaN  \n",
       "1990-01-08          NaN           NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Market_Features_to_drop = ['Volume','High','Low','Adj Close']\n",
    "Balance_sheet_features_to_keep = ['totalAssets','totalShareholderEquity']\n",
    "\n",
    "# Get Price Data\n",
    "SP500_raw_df = pd.read_csv(sp500_csv, index_col = 'Date')\n",
    "VIX_raw_df = pd.read_csv(vix_csv, index_col = 'Date')\n",
    "JJ_raw_price_df = pd.read_csv(jj_csv, index_col = 'Date')\n",
    "\n",
    "# Get Quarterly Data\n",
    "JJ_Earnings_df = pd.read_csv(jj_earnings_csv)\n",
    "JJ_Earnings_df['Date'] = pd.to_datetime(JJ_Earnings_df['Fiscal Date'])\n",
    "JJ_Earnings_df.drop(columns = ['Fiscal Date'], inplace = True)\n",
    "JJ_Earnings_df.set_index('Date', inplace = True)\n",
    "JJ_Earnings_df =  JJ_Earnings_df.iloc[::-1]\n",
    "\n",
    "JJ_BalSht_df = pd.read_csv(jj_balSht_csv)\n",
    "JJ_BalSht_df['Date'] = pd.to_datetime(JJ_BalSht_df['fiscalDateEnding'])\n",
    "JJ_BalSht_df.drop(columns = ['fiscalDateEnding'], inplace = True)\n",
    "JJ_BalSht_df.set_index('Date', inplace = True)\n",
    "JJ_BalSht_df =  JJ_BalSht_df.iloc[::-1]\n",
    "\n",
    "# get Dividend Data\n",
    "JJ_dividend_df = pd.read_csv(jj_dividend_csv)\n",
    "JJ_dividend_df['Date'] = JJ_dividend_df['Date'].str.split().str[0]\n",
    "JJ_dividend_df.set_index('Date', inplace = True)\n",
    "\n",
    "# drop market feature form S&P and VIX\n",
    "SP500_raw_df.drop(columns= Market_Features_to_drop, inplace= True)\n",
    "VIX_raw_df.drop(columns=Market_Features_to_drop, inplace= True)\n",
    "\n",
    "# drop high and low\n",
    "JJ_raw_price_df.drop(columns=['High','Adj Close', 'Low'], inplace=True)\n",
    "\n",
    "# Calculate daily return\n",
    "SP500_raw_df['Daily_Return_dollars'] = SP500_raw_df['Close'] - SP500_raw_df['Open']\n",
    "VIX_raw_df['Daily_Return_dollars'] = VIX_raw_df['Close'] - VIX_raw_df['Open']\n",
    "\n",
    "SP500_raw_df['Daily_Return_percent'] = SP500_raw_df['Daily_Return_dollars']/SP500_raw_df['Open']\n",
    "VIX_raw_df['Daily_Return_percent'] = VIX_raw_df['Daily_Return_dollars']/VIX_raw_df['Open']\n",
    "\n",
    "JJ_raw_price_df['Daily_Return_dollars'] = JJ_raw_price_df['Close'] - JJ_raw_price_df['Open']\n",
    "JJ_raw_price_df['Daily_Return_percent'] = JJ_raw_price_df['Daily_Return_dollars']/JJ_raw_price_df['Open']\n",
    "\n",
    "# drop open and close\n",
    "JJ_raw_price_df.drop(columns=['Open','Close','Daily_Return_dollars'], inplace = True)\n",
    "SP500_raw_df.drop(columns=['Open','Close','Daily_Return_dollars'], inplace = True)\n",
    "VIX_raw_df.drop(columns=['Open','Close','Daily_Return_dollars'], inplace = True)\n",
    "\n",
    "# Balance Sheet Features\n",
    "JJ_Bal_Sheet_reduced_df = JJ_BalSht_df.loc[:,Balance_sheet_features_to_keep]\n",
    "JJ_Bal_Sheet_reduced_df['Equity Ratio'] = JJ_Bal_Sheet_reduced_df['totalShareholderEquity'] /JJ_Bal_Sheet_reduced_df['totalAssets']\n",
    "JJ_Bal_Sheet_reduced_df.drop(columns=['totalShareholderEquity'], inplace = True)\n",
    "\n",
    "# JJ merge\n",
    "JJ_market_df = JJ_dividend_df.merge(JJ_raw_price_df, left_index=True, right_index=True)\n",
    "JJ_market_df.index = pd.to_datetime(JJ_market_df.index)\n",
    "JJ_earnbal_df = JJ_Earnings_df.merge(JJ_Bal_Sheet_reduced_df, left_index = True, right_index = True)\n",
    "JJ_merge_df = JJ_market_df.merge(JJ_earnbal_df,how = 'outer', left_index= True, right_index= True)\n",
    "\n",
    "# Merge Raw Data\n",
    "market_df = SP500_raw_df.merge(VIX_raw_df, left_index=True, right_index=True,suffixes=('_SP','_VIX'))\n",
    "market_df.index = pd.to_datetime(market_df.index)\n",
    "\n",
    "merged_df = market_df.merge(JJ_merge_df, how = 'outer', left_index= True, right_index= True)\n",
    "# Display Data Frame Head\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of the Final Features/ Target and train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN (Franco)\n",
    "\n",
    "## Why this model for this problem\n",
    "\n",
    "* Recurrent nerual networks are specifically designed to handle sequential data, ideal for time-series forecasting. gated neural networks like the LSTM offer nuanced pattern recognition and adapt to macroeconomic trends and cycles over time.\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "## Model Specific Preprocessing \n",
    "\n",
    "## Model Specific Tuning\n",
    "\n",
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitted Model and Results\n",
    "    - Report on hyper parameters\n",
    "    - Report on fit quality\n",
    "    - Ideas on improvement if the model was continued to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN results (Franco)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost (Hank)\n",
    "## Why this model for this problem\n",
    "## Model Architecture\n",
    "## Model Specific Preprocessing \n",
    "## Model Specific Tuning\n",
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitted Model and Results\n",
    "    - Report on hyper parameters\n",
    "    - Report on fit quality\n",
    "    - Ideas on improvement if the model was continued to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (Bhavesh)\n",
    "## Why this model for this problem\n",
    "## Model Architecture\n",
    "## Model Specific Preprocessing \n",
    "## Model Specific Tuning\n",
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitted Model and Results\n",
    "    - Report on hyper parameters\n",
    "    - Report on fit quality\n",
    "    - Ideas on improvement if the model was continued to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmeans Regimes + Markov Chain (Kevin)\n",
    "## Why this model for this problem\n",
    "## Model Architecture\n",
    "## Model Specific Preprocessing \n",
    "## Model Specific Tuning\n",
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitted Model and Results\n",
    "    - Report on hyper parameters\n",
    "    - Report on fit quality\n",
    "    - Ideas on improvement if the model was continued to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
