{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Branch\n",
    "I will work here before merging with main so we have a backup in case someone messes up a merge with their independent branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Modules for fetching data\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "AV_api_key = os.getenv(\"ALPHA_VANTAGE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data retrieval and cleanup helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def DeleteEmptyCSVs(CSVToCheck):\n",
    "    # Function to delete any csvs that were created by an attempted data retrieval\n",
    "    # but are empty of data\n",
    "    if os.path.isfile(CSVToCheck):\n",
    "        # Count the number of lines in the file\n",
    "        with open(CSVToCheck, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            line_count = sum(1 for row in reader)\n",
    "        \n",
    "        print(f\"The file {CSVToCheck} has {line_count} lines.\")\n",
    "\n",
    "        # Check if the line count is less 3 (header and empty line)\n",
    "        if line_count < 3:\n",
    "            print(f\"{CSVToCheck} seems empty. Deleting the file.\")\n",
    "            os.remove(CSVToCheck)\n",
    "        else:\n",
    "            print(f\"{CSVToCheck} seems to have data.\")\n",
    "    else:\n",
    "        print(f\"{CSVToCheck} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getYahoo(tckr, tckr_csv):\n",
    "    \n",
    "    if not os.path.isfile(tckr_csv):\n",
    "        print(\"Retrieving \"+tckr+\" Data from Yahoo...\")\n",
    "        try:\n",
    "            tckr_data = yf.download(sp500_ticker, start=START_DATE_sp500, end=END_DATE_sp500)\n",
    "            print(\"saving data to csv\")\n",
    "            tckr_data.to_csv(tckr_csv)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to retrieve data: {e}\")\n",
    "    else:\n",
    "        print(tckr+\" data already saved in csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDividends(tckr):\n",
    "    ticker = yf.Ticker(tckr)\n",
    "    dividends_series = ticker.dividends\n",
    "    csvFile = '.\\data_files\\\\'\n",
    "    csvFile = csvFile + tckr + 'dividends.csv'\n",
    "    dividends_series.to_csv(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEarningsFromAlphaVantage(stock_ticker, data_folder = 'data_files'):\n",
    "    # Request from API\n",
    "    url = f'https://www.alphavantage.co/query?function=EARNINGS&symbol={stock_ticker}&apikey={AV_api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    quarterly_file =  stock_ticker + 'quarterlyEarnings.csv'\n",
    "    #annual_file =  stock_ticker + 'annualEarnings.csv'\n",
    "    quarterly_csv = os.path.join(data_folder, quarterly_file)\n",
    "    #annual_csv = os.path.join(data_folder, annual_file)\n",
    "    # Parse the response to get EPS data and save it as a CSV file\n",
    "    quarterly_earnings = data['quarterlyEarnings']\n",
    "    #annual_earnings = data['annualEarnings']\n",
    "    if not os.path.isfile(quarterly_csv):\n",
    "        with open(quarterly_csv, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Fiscal Date','Estimated EPS', 'Reported EPS'])  # Write header row\n",
    "            for earnings_data in quarterly_earnings:\n",
    "                fiscal_date = earnings_data['fiscalDateEnding']\n",
    "                estimated_eps = earnings_data['estimatedEPS']\n",
    "                reported_eps = earnings_data['reportedEPS']\n",
    "                writer.writerow([fiscal_date, estimated_eps, reported_eps])\n",
    "    else:\n",
    "        print(\"Quarterly Earnings CSV already present\")\n",
    "    # Report save\n",
    "        \n",
    "    print(f\" Quarterly Earnings data saved to {quarterly_csv}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BalanceSheetFromAlphaVantage(stock_ticker, data_folder = 'data_files'):\n",
    "    # Request from API\n",
    "    url = 'https://www.alphavantage.co/query?function=BALANCE_SHEET&symbol=IBM&apikey=demo'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    quarterly_file =  stock_ticker + 'quarterlyBalSheet.csv'\n",
    "    #annual_file =  stock_ticker + 'annualEarnings.csv'\n",
    "    quarterly_csv = os.path.join(data_folder, quarterly_file)\n",
    "    #annual_csv = os.path.join(data_folder, annual_file)\n",
    "    # Parse the response to get EPS data and save it as a CSV file\n",
    "    quarterly_reports = data['quarterlyReports']\n",
    "    #annual_earnings = data['annualEarnings']\n",
    "    if not os.path.isfile(quarterly_csv):\n",
    "        with open(quarterly_csv, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            balance_sheet_items = list(quarterly_reports[0].keys())\n",
    "            writer.writerow(balance_sheet_items)  # Write header row\n",
    "            for report in quarterly_reports:\n",
    "                curr_row = []\n",
    "                for item in balance_sheet_items:\n",
    "                    curr_row.append(report[item])\n",
    "                writer.writerow(curr_row)\n",
    "    else:\n",
    "        print(\"Quarterly Earnings CSV already present\")\n",
    "    # Report save\n",
    "        \n",
    "    print(f\" Quarterly Earnings data saved to {quarterly_csv}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Initial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sourced from yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE_yahoo =\"1990-01-01\"\n",
    "END_DATE_yahoo = \"2024-05-30\"\n",
    "\n",
    "# Larger Market trends \n",
    "\n",
    "# S&P 500\n",
    "sp500_ticker = '^GSPC'\n",
    "sp500_csv = '.\\data_files\\sp500_RawData.csv'\n",
    "START_DATE_sp500 = START_DATE_yahoo\n",
    "END_DATE_sp500 = END_DATE_yahoo\n",
    "\n",
    "# CBOE Volatility Index (VIX)\n",
    "vix_ticker = '^VIX'\n",
    "vix_csv = '.\\data_files\\VIX_RawData.csv'\n",
    "START_DATE_vix = START_DATE_yahoo\n",
    "END_DATE_vix = END_DATE_yahoo\n",
    "\n",
    "# Large Cap Stocks\n",
    "\n",
    "# Microsoft (MSFT)\n",
    "micro_ticker = 'MSFT'\n",
    "micro_csv = '.\\data_files\\MSFT_RawData.csv'\n",
    "START_DATE_msft = START_DATE_yahoo\n",
    "END_DATE_msft = END_DATE_yahoo\n",
    "\n",
    "# General Electric (GE)\n",
    "general_elec_ticker = 'GE'\n",
    "ge_csv = '.\\data_files\\GE_RawData.csv'\n",
    "START_DATE_ge = START_DATE_yahoo\n",
    "END_DATE_ge = END_DATE_yahoo\n",
    "\n",
    "# Johnson and Johnson (JNJ)\n",
    "jj_ticker = 'JNJ'\n",
    "jj_csv = '.\\data_files\\JNJ_RawData.csv'\n",
    "START_DATE_jj = START_DATE_yahoo\n",
    "END_DATE_jj = END_DATE_yahoo\n",
    "\n",
    "# Coca Cola (KO)\n",
    "cc_ticker = 'KO'\n",
    "cc_csv = '.\\data_files\\KO_RawData.csv'\n",
    "START_DATE_cc = START_DATE_yahoo\n",
    "END_DATE_cc = END_DATE_yahoo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 (representative of of larger market trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&P data already saved in csv\n",
      "The file .\\data_files\\sp500_RawData.csv has 11197 lines.\n",
      ".\\data_files\\sp500_RawData.csv seems to have data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.isfile(sp500_csv):\n",
    "    print(\"Retrieving S&P Data from Yahoo...\")\n",
    "    try:\n",
    "        sp500_data = yf.download(sp500_ticker, start=START_DATE_sp500, end=END_DATE_sp500)\n",
    "        print(\"saving data to csv\")\n",
    "        sp500_data.to_csv(sp500_csv)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve data: {e}\")\n",
    "else:\n",
    "    print(\"S&P data already saved in csv\")\n",
    "\n",
    "DeleteEmptyCSVs(sp500_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIX (overall market volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIX data already saved in csv\n",
      "The file .\\data_files\\VIX_RawData.csv has 8669 lines.\n",
      ".\\data_files\\VIX_RawData.csv seems to have data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.isfile(vix_csv):\n",
    "    print(\"Retrieving \"+vix_ticker+\"from Yahoo...\")\n",
    "    try:\n",
    "        vix_data = yf.download(vix_ticker, start=START_DATE_vix, end=END_DATE_vix)\n",
    "        print(\"saving data to csv\")\n",
    "        vix_data.to_csv(vix_csv)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve data: {e}\")\n",
    "else:\n",
    "    print(\"VIX data already saved in csv\")\n",
    "\n",
    "DeleteEmptyCSVs(vix_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.isfile(sp500_csv):\n",
    "    print(\"Retrieving S&P Data from Yahoo...\")\n",
    "    try:\n",
    "        sp500_data = yf.download(sp500_ticker, start=START_DATE_sp500, end=END_DATE_sp500)\n",
    "        print(\"saving data to csv\")\n",
    "        sp500_data.to_csv(sp500_csv)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve data: {e}\")\n",
    "else:\n",
    "    print(\"S&P data already saved in csv\")\n",
    "\n",
    "DeleteEmptyCSVs(sp500_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving JNJ Data from Yahoo...\n",
      "saving data to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "getYahoo(jj_ticker, jj_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving MSFT Data from Yahoo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "getYahoo(micro_ticker,micro_csv)\n",
    "getYahoo(micro_ticker,micro_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "getDividends(jj_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "getDividends(micro_ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Vantage Accounting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BalanceSheetFromAlphaVantage(stock_ticker=micro_ticker)\n",
    "#GetEarningsFromAlphaVantage(stock_ticker= micro_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Quarterly Earnings data saved to data_files\\JNJquarterlyBalSheet.csv\n",
      " Quarterly Earnings data saved to data_files\\JNJquarterlyEarnings.csv\n"
     ]
    }
   ],
   "source": [
    "BalanceSheetFromAlphaVantage(stock_ticker=jj_ticker)\n",
    "GetEarningsFromAlphaVantage(stock_ticker= jj_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
